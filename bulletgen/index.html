
<!DOCTYPE html>
<html>

<head lang="en">
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-XXMBYZ9G6R"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-XXMBYZ9G6R');
    </script>
    
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>BulletGen</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://rozumden.github.io/bulletgen/img/teaser.png">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1296">
    <meta property="og:image:height" content="840">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://rozumden.github.io/bulletgen/"/>
    <meta property="og:title" content="BulletGen: Improving 4D Reconstruction with Bullet-Time Generation" />
    <meta property="og:description" content="Transforming casually captured, monocular videos into fully immersive dynamic experiences is a highly ill-posed task, and comes with significant challenges, e.g., reconstructing unseen regions, and dealing with the ambiguity in monocular depth estimation. In this work we introduce BulletGen, an approach that takes advantage of generative models to correct errors and complete missing information in a Gaussian-based dynamic scene representation. This is done by aligning the output of a diffusion-based video generation model with the 4D reconstruction at a single frozen bullet-time step. The generated frames are then used to supervise the optimization of the 4D Gaussian model. Our method seamlessly blends generative content with both static and dynamic scene components, achieving state-of-the-art results on both novel-view synthesis, and 2D/3D tracking tasks." />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="BulletGen: Improving 4D Reconstruction with Bullet-Time Generation" />
    <meta name="twitter:description" content="Transforming casually captured, monocular videos into fully immersive dynamic experiences is a highly ill-posed task, and comes with significant challenges, e.g., reconstructing unseen regions, and dealing with the ambiguity in monocular depth estimation. In this work we introduce BulletGen, an approach that takes advantage of generative models to correct errors and complete missing information in a Gaussian-based dynamic scene representation. This is done by aligning the output of a diffusion-based video generation model with the 4D reconstruction at a single frozen bullet-time step. The generated frames are then used to supervise the optimization of the 4D Gaussian model. Our method seamlessly blends generative content with both static and dynamic scene components, achieving state-of-the-art results on both novel-view synthesis, and 2D/3D tracking tasks." />
    <meta name="twitter:image" content="https://rozumden.github.io/bulletgen/img/teaser.png" />


<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚡</text></svg>">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
    <script src="js/video_comparison.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>BulletGen</b>: Improving 4D Reconstruction with Bullet-Time Generation</br> 
                <small>
                arXiv 2025
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://rozumden.github.io/">
                          Denys Rozumnyi
                        </a>
                    </li>
                    <li>
                        <a href="https://scholar.google.de/citations?user=XpOqG0cAAAAJ/">
                            Jonathon Luiten
                        </a>
                    </li>
                    <li>
                        <a href="https://scholar.google.com/citations?user=B_mk94MAAAAJ/">
                          Numair Khan
                        </a>
                    </li>
                    <li>
                        <a href="https://demuc.de/">
                          Johannes Schönberger
                        </a>
                    </li>
                    <li>
                        <a href="https://scholar.google.com/citations?user=CxbDDRMAAAAJ/">
                          Peter Kontschieder
                        </a>
                    </li>
                    </br>Meta Reality Labs
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-6 col-md-offset-3 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/abs/2506.18601">
                            <image src="img/arxiv.png" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <!-- <li>
                            <a href="https://www.youtube.com/watch?v=xrrhynRzC8k">
                            <image src="img/youtube_icon.png" height="60px">
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li> -->
<!--                         <li>
                            <a href="https://github.com/jonbarron/camp_zipnerf">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li> -->
                    </ul>
                </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/cat.mp4" type="video/mp4" />
                </video>
						</div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
Transforming casually captured, monocular videos into fully immersive dynamic experiences is a highly ill-posed task, and comes with significant challenges, e.g., reconstructing unseen regions, and dealing with the ambiguity in monocular depth estimation. In this work we introduce BulletGen, an approach that takes advantage of generative models to correct errors and complete missing information in a Gaussian-based dynamic scene representation. This is done by aligning the output of a diffusion-based video generation model with the 4D reconstruction at a single frozen "bullet-time" step. The generated frames are then used to supervise the optimization of the 4D Gaussian model. Our method seamlessly blends generative content with both static and dynamic scene components, achieving state-of-the-art results on both novel-view synthesis, and 2D/3D tracking tasks.
                </p>
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Pipeline
                </h3>
                BulletGen architecture. Starting from a monocular RGB video, we reconstruct the
dynamic scene with Shape-of-Motion given data-driven priors (motion masks, depths, longterm 2D tracks). Then, we generate novel views at selected frozen timesteps (bullet times) using
a conditioned generative model. These generated views are localized and mapped to the current
scene using an optimization based on photometric, perceptual, semantic, and depth errors. Final 4D
reconstruction augments the scene and allows for higher quality extreme novel view synthesis.
<br>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="img/pipeline.mp4" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div>
<br>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results on the DyCheck iPhone dataset
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="img/dog.mp4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div>
<br>
    <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results on the NVIDIA dynamic dataset
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="img/spin.mp4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="img/windmill.mp4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div>
<br>
        
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@misc{rozumnyi2025bulletgenimproving4dreconstruction,
      title={BulletGen: Improving 4D Reconstruction with Bullet-Time Generation}, 
      author={Denys Rozumnyi and Jonathon Luiten and Numair Khan and Johannes Schönberger and Peter Kontschieder},
      year={2025},
      eprint={2506.18601},
      archivePrefix={arXiv},
      primaryClass={cs.GR},
      url={https://arxiv.org/abs/2506.18601}, 
}</textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <!-- <p class="text-justify">
                Thanks to Janne Kontkanen, Rick Szeliski, and David Salesin for their comments on the text, and to Ricardo Martin-Brualla, Keunhong Park, Ben Poole, Aleksander Hołyński, Etienne Pot, Kostas Rematas, Daniel Duckworth, Marcos Seefelder, Cardin Moffett, and Peter Zhizhin for their advice and help. -->
                    <!-- <br><br> -->
                The website template was borrowed from <a href="http://mgharbi.com/">Michaël Gharbi</a> and <a href="https://dorverbin.github.io/refnerf">Ref-NeRF</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
